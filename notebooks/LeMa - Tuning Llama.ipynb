{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this tutorial, we'll focus on how you can easily tune various flavors of Llama. For simplicity, we'll be using Polaris as the platform for compute.\n",
    "\n",
    "**NOTE:** This tutorial builds off of our [Finetuning Tutorial](https://github.com/openlema/lema/blob/main/notebooks/LeMa%20-%20Finetuning%20Tutorial.ipynb). We recommend starting there first to get a thorough understanding of how tuning works in our library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial assumes:\n",
    "- You have a valid ALCF account with access to Polaris\n",
    "- You're familiar with our tuning flow\n",
    "- You're familiar with how to launch lema workflows on Polaris. [Here's a relevant tutorial](https://github.com/openlema/lema/blob/main/notebooks/LeMa%20-%20Deploying%20a%20Job.ipynb)\n",
    "- You've signed [Llama's agreement on HuggingFace](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Llama\n",
    "\n",
    "We currently have out-of-the-box tuning jobs configured for the following flavors of Llama:\n",
    "\n",
    "- Llama3.1 8b LoRA: [configs/lema/jobs/polaris/llama8b_lora.yaml](https://github.com/openlema/lema/blob/main/configs/lema/jobs/polaris/llama8b_lora.yaml) âœ¨\n",
    "- Llama3.1 8b SFT   â€“ COMING SOON! ðŸš€\n",
    "- Llama3.1 70b LoRA â€“ COMING SOON! ðŸš€\n",
    "- Llama3.1 70b SFT  â€“ COMING SOON! ðŸš€\n",
    "\n",
    "## Llama 3.1 8b LoRA\n",
    "\n",
    "By default our tuning job will run using the [`yahma/alpaca-cleaned`](https://huggingface.co/datasets/yahma/alpaca-cleaned) dataset. This is configured in [configs/lema/llama8b.lora.yaml](https://github.com/openlema/lema/blob/main/configs/lema/llama8b.lora.yaml). We strongly suggest tuning these parameters as needed for your specific run.\n",
    "\n",
    "Before running the job, ensure you've signed Llama's agreement on HuggingFace and have obtained your [HF_TOKEN](https://huggingface.co/docs/huggingface_hub/en/package_reference/environment_variables#hftoken). We'll pass it to our job by appending envs.HF_TOKEN=$HF_TOKEN to our launcher script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```shell\n",
    "lema-launch -p /configs/lema/jobs/polaris/llama8b_lora.yaml envs.HF_TOKEN=$HF_TOKEN user=$ALCF_USER\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
